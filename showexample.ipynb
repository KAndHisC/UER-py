{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, GPT2LMHeadModel, TextGenerationPipeline\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"uer/gpt2-chinese-lyric\")\n",
    "# model = GPT2LMHeadModel.from_pretrained(\"uer/gpt2-chinese-lyric\")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"/home/wangshichuan/workspace/python/UER-py/myspace/clyric\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"/home/wangshichuan/workspace/python/UER-py/myspace/clyric\")\n",
    "\n",
    "text_generator = TextGenerationPipeline(model, tokenizer)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '梅花落满了南山 / n 一 片 云 烟 云 烟 / n 花 枝 花 开 了 / n 远 去 的 风 雨 / n 花 朵 开 花 / n 在 山 野 上 / n 在 山 峰 上 / n 我 在 云 中 / n 山 脉 里 / n 风 吹 起 来 / n 一 株 花 朵 云 烟 / n 风 吹 来 / n 风 雨 的 山 峰 上 / n 风 吹 过 山 林 / n 风 在 云 中 / n 风 吹 过 山 / n 我 的 山 峰 / n 风 吹 过 来 / n 山 峰 是 山 峰 / n 我 是 一 样 / n 山 峰 / n 在 山 峰 上 / n 一 片 云 烟 / n 我 的 月 亮 / n 我 的 山 谷 / n 在 风 中 / n 一 株 株 / n 在 月 亮 / n / n / n 我 曾 经 有 风 / n 我 要 说 / n 月 色 的 山 峰 / n 在 风 里 / n 山 风 吹 到 了 / n 风 雨 / n 过 山 坡 / n 风 / n 风 中 / n / n 在 / n 我 的 山 峰 / n 一 株 树 / n 山 谷 / n 月 色 的 山 野'},\n",
       " {'generated_text': '梅花落满了南山 的 花 / n 秋 风 琴 / n 秋 天 是 黄 叶 / n 秋 天 的 秋 天 / n 秋 天 的 秋 天 是 冬 天 的 野 花 / n 是 黄 叶 的 野 花 飘 落 / n 秋 天 的 野 花 飘 落 / n 黄 金 的 落 叶 / n 秋 天 的 落 日 / n 黄 叶 在 落 叶 飘 落 落 花 / n 秋 天 的 风 霜 雪 落 落 / n 落 叶 飘 落 的 雪 落 / n 红 云 秋 风 / n 秋 风 飘 落 的 落 叶 / n 黄 叶 / n 落 落 在 秋 叶 飘 落 的 冬 天 / n 秋 天 的 雪 落 / n 落 叶 落 在 落 叶 飘 落 / n 落 在 秋 天 的 风 / n 落 叶 落 的 雪 落 在 雪 叶 / n 秋 天 的 落 叶 的 雪 花 / n 秋 天 的 风 雪 / n 落 叶 / n 雪 花 飘 落 的 秋 天 的 雪 落 在 雪 地 落 叶 飘 落 在 风 飘 飘 落 / n 雪 落 在 落 叶 的 雪 飘 落 / n 落 在 冬 晚 / n 雪 落 / n 雪 落 落 叶 飘 飘 落 / n 雪 中 秋 天 / n 雪 落'},\n",
       " {'generated_text': '梅花落满了南山 ， / n 山 谷 在 山 谷 上 的 山 谷 ， / n 犹 如 山 上 山 谷 的 山 谷 ， / n 在 山 谷 里 ， / n 一 如 山 谷 里 ， / n 山 谷 里 ， 山 谷 里 犹 似 的 山 谷 ， / n 在 山 谷 里 ， / n 山 谷 里 ， / n 山 谷 在 山 谷 上 的 山 谷 里 ， / n 山 谷 里 ， / n 山 谷 里 ， / n 在 山 谷 上 ， / n 山 山 ， / n 是 山 谷 的 山 谷 里 ， / n 一 片 云 山 谷 的 山 谷 ， / n 在 山 谷 中 。 / n 山 谷 ， / n 是 山 谷 中 ， / n 是 山 谷 里 ， / n 山 谷 里 ， / n 犹 似 的 山 谷 ， / n 是 山 谷 ， / n 是 古 铜 色 的 山 谷 ， / n 在 山 谷 中 ， / n 在 山 谷 里 。 / n 山 谷 ， / n 月 谷 里 ， / n 在 山 谷 里 ， / n 月 光 中 山 谷 鸟 ， / n 山 谷 ， / n 月 色 山 谷 里 ， / n 山 谷 中 的 ， / n 古 色 ， /'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generator(\"梅花落满了南山\", max_length=256, do_sample=True,top_k=5, top_p=0.95, num_return_sequences=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[{'generated_text': '夜空中最亮的星， 这 是 爱 ， 就 此 一 生 ， 愿 我 的 我 的 吻 ， 一 再 爱 ， 也 许 是 我 真 ， 想 对 你 ， 狂 妄 代 价 ， 会 些 为 了 ， 这 种 罪 ， 我 爱 你 ， 没 有 未 能 令 我 的 手 ， 嗯 。 ， 不 要 独 立 生 活 下 也 记 忆 为 我 们 的 心 恼 ， 明 天 可 躲 ， 当 我 的 我 这 单 车 ， 失'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '{冬}<3>[梅花,雪,寒冷,思念]梅花落满了南山，像一地的雪， ， ， ， 一 样 。 ， 的 海 滩 的 小 草 滩 ， ， ， 还 是 得 很 早 年 的 ， 在 海 洋 的 的 人 类 似 的 时 间 的 尽 头 ， 。 ， ， 的 得 很 远 方 ， 我 的 的 一 个 时 候 。 ， 地 上'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generator(\"{冬}<3>[梅花,雪,寒冷,思念]梅花落满了南山，像一地的雪，\", max_length=128, do_sample=True,top_k=5, top_p=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator(\"最美的不是下雨天，是曾与你躲过雨的屋檐\", max_length=256, do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator(\"当两颗心开始震动,当你瞳孔学会闪躲\", max_length=100, do_sample=True)\n",
    "text_generator(\"当两颗心开始震动,当你瞳孔学会闪躲\", max_length=100, do_sample=True,     top_k=5, top_p=0.9, num_return_sequences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator(\"当 两 颗 心 开 始 震 动 \", max_length=100, do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator(\"当两颗心开始震动，\", max_length=100, do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, GPT2LMHeadModel, TextGenerationPipeline\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"uer/gpt2-chinese-lyric\")\n",
    "# model = GPT2LMHeadModel.from_pretrained(\"uer/gpt2-chinese-lyric\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"/localdata/workspace/UER-py/models/clyric\")\n",
    "model = GPT2LMHeadModel.from_pretrained('/localdata/workspace/UER-py/models/clyric')\n",
    "text_generator = TextGenerationPipeline(model, tokenizer)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " [{'generated_text': '最美的不是下雨天，是曾与你躲过雨的屋檐 ， 下 课 铃 声 响 起 的 瞬 间 ， 我 们 的 笑 脸 ， 有 太 多 回 忆 在 浮 现 ， 是 你 总 在 我 身 边 ， 不 知 道 会 不 会 再 见 ， 从 现 在 开 始 到 永 远 ， 想 说 的 语 言 凝 结 成 一 句 ， 不 管 我 们 是 否 能 够 兑 现 ， 想 说 的 语 言 凝 结'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaj/miniconda3/envs/uer/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading: 100%|██████████| 713k/713k [00:01<00:00, 676kB/s]  \n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nTFGPT2LMHeadModel requires the TensorFlow library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://www.tensorflow.org/install and follow the ones that match your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[39mreturn\u001b[39;00m text\n\u001b[1;32m     16\u001b[0m tokenizer \u001b[39m=\u001b[39m XLNetTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m'\u001b[39m\u001b[39mmymusise/CPM-Generate-distill\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m model \u001b[39m=\u001b[39m TFGPT2LMHeadModel\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mmymusise/CPM-Generate-distill\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     19\u001b[0m text_generater \u001b[39m=\u001b[39m TextGenerationPipeline(model, tokenizer)\n\u001b[1;32m     21\u001b[0m \u001b[39mprint\u001b[39m(text_generater(\u001b[39m\"\u001b[39m\u001b[39m天下熙熙，\u001b[39m\u001b[39m\"\u001b[39m, max_length\u001b[39m=\u001b[39m\u001b[39m15\u001b[39m, top_k\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, use_cache\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, prefix\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/uer/lib/python3.8/site-packages/transformers-4.6.1-py3.8.egg/transformers/utils/dummy_tf_objects.py:955\u001b[0m, in \u001b[0;36mTFGPT2LMHeadModel.from_pretrained\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    954\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_pretrained\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 955\u001b[0m     requires_backends(\u001b[39mself\u001b[39;49m, [\u001b[39m\"\u001b[39;49m\u001b[39mtf\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "File \u001b[0;32m~/miniconda3/envs/uer/lib/python3.8/site-packages/transformers-4.6.1-py3.8.egg/transformers/file_utils.py:569\u001b[0m, in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m    567\u001b[0m name \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    568\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(BACKENDS_MAPPING[backend][\u001b[39m0\u001b[39m]() \u001b[39mfor\u001b[39;00m backend \u001b[39min\u001b[39;00m backends):\n\u001b[0;32m--> 569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([BACKENDS_MAPPING[backend][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mformat(name) \u001b[39mfor\u001b[39;00m backend \u001b[39min\u001b[39;00m backends]))\n",
      "\u001b[0;31mImportError\u001b[0m: \nTFGPT2LMHeadModel requires the TensorFlow library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://www.tensorflow.org/install and follow the ones that match your environment.\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLNetTokenizer, GPT2LMHeadModel\n",
    "from transformers import TextGenerationPipeline\n",
    "import jieba\n",
    "# add spicel process \n",
    "class XLNetTokenizer(XLNetTokenizer):\n",
    "    translator = str.maketrans(\" \\n\", \"\\u2582\\u2583\")\n",
    "    def _tokenize(self, text, *args, **kwargs):\n",
    "        text = [x.translate(self.translator) for x in jieba.cut(text, cut_all=False)]\n",
    "        text = \" \".join(text)\n",
    "        return super()._tokenize(text, *args, **kwargs)\n",
    "    def _decode(self, *args, **kwargs):\n",
    "        text = super()._decode(*args, **kwargs)\n",
    "        text = text.replace(' ', '').replace('\\u2582', ' ').replace('\\u2583', '\\n')\n",
    "        return text\n",
    "\n",
    "tokenizer = XLNetTokenizer.from_pretrained('mymusise/CPM-Generate-distill')\n",
    "model = GPT2LMHeadModel.from_pretrained(\"mymusise/CPM-Generate-distill\")\n",
    "\n",
    "text_generater = TextGenerationPipeline(model, tokenizer)\n",
    "\n",
    "print(text_generater(\"天下熙熙，\", max_length=15, top_k=1, use_cache=True, prefix=''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator('梅花开在南山上，', max_length=50, do_sample=True, top_p=0.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49a4d35495a0ee52f35720c27c94986b4a3077a71a8c6157808376aed5c51fad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
