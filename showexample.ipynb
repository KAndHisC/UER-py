{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, GPT2LMHeadModel, TextGenerationPipeline\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"uer/gpt2-chinese-lyric\")\n",
    "# model = GPT2LMHeadModel.from_pretrained(\"uer/gpt2-chinese-lyric\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"/data/workspace/PKU/UER-py/models/sanwen\")\n",
    "model = GPT2LMHeadModel.from_pretrained('/data/workspace/PKU/UER-py/models/sanwen')\n",
    "text_generator = TextGenerationPipeline(model, tokenizer)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '在各自的↲不同的象限里↲我看到生活↲总有一种↲与众不同的↲ 与 众 不 同 的 ↲ 与 众 不 同 的 ↲↲ 啊 ↲ 最 终 有 一 天 ↲ 我 也 不 得 不 ↲ 在 我 后 面 ↲ 跟 一 个 陌 生 人 说 话 ↲ 他 就 是 那 个 ↲ 唱 着 歌 来 的 ↲ 唱 着 歌 来 的 ↲ 他 就 开 始 变 得 ↲ 其 实 ↲ 一 直 就 是 ↲ 一 直 到 ↲ 我 不 再 想 说 的 ↲ 也 不 再 想 说 ↲↲ 就 是 结 婚 以 后 ↲ 你 就 出 来 了 ↲ 一 个 人 ↲ 一 个 人 ↲ 在 酒 馆 里 ↲ 喝 着 茶 ↲ 聊 着 天 ↲↲ 我 就 出 来 了 ↲ 象 你 一 样 ↲ 看 着 我 ↲ 开 始 ↲ 以 来 ↲ 就 是 一 件 事 情 ↲ 桌 子 ↲ 空 着 ↲↲ ↲ ↲ ↲ ↲ ↲ ↲ ↲ ↲ ↲ ↲ 一 切 ↲ 话 ↲ ↲ ↲ ↲ ↲ ↲ 一 切 ↲ — — — —'},\n",
       " {'generated_text': '在各自的↲不同的象限里↲我看到生活↲总有一种↲与众不同的↲ 与 众 不 同 的 ↲ 与 众 不 同 的 ↲ 与 众 不 同 的 ↲↲ 在 这 里 ↲ 最 终 的 情 感 ↲ 就 是 诗 ↲ 所 体 现 的 ↲ 最 真 的 ↲ 也 是 最 美 的 ↲ 万 物 的 本 质 ↲ 都 是 为 死 而 生 的 ↲ 他 们 都 在 这 里 ↲ 死 去 ↲ 不 死 ↲ 不 死 ↲ 也 没 有 灵 魂 ↲↲ 我 ↲ 只 好 紧 紧 ↲ 抱 着 这 一 切 ↲ 我 四 处 寻 找 ↲ 找 到 一 个 名 字 ↲ 名 字 叫 做 ↲ 故 乡 ↲ 故 乡 ↲ 的 一 切 ↲ 我 在 这 里 ↲↲ 我 们 就 要 分 手 ↲ 在 这 里 ↲ 就 要 分 手 ↲ 在 这 里 ↲ 在 这 里 ↲ 又 是 一 个 ↲ 又 是 一 个 ↲ 又 是 一 个 ↲ ↲ ↲ 那 天 ↲ 有 人 破 晓 ↲ 什 么 也 没 有 破 晓 ↲ 什 么 也 没 破 晓 ↲ — — ↲ 呵 ↲'},\n",
       " {'generated_text': '在各自的↲不同的象限里↲我看到生活↲总有一种↲与众不同的↲ 与 众 不 同 的 ↲ 与 众 不 同 的 ↲↲ 在 这 里 ↲ 是 一 片 ↲ 辽 阔 的 大 海 ↲ 和 大 河 ↲ 我 想 ↲ 在 这 里 ↲ 会 和 许 多 人 分 享 ↲ 生 活 的 闪 耀 ↲ 以 及 ↲ 生 活 中 ↲ 所 遇 到 的 一 些 ↲ 无 法 解 释 的 问 题 ↲↲ 在 这 里 ↲ 也 会 出 现 ↲ 无 法 解 释 的 问 题 ↲ 我 想 ↲ 在 这 里 ↲ 也 会 出 现 ↲ 多 少 次 ↲ 我 自 己 ↲ 也 不 知 道 ↲ 是 出 于 什 么 原 因 ↲ 在 这 里 ↲ 会 出 现 ↲ 这 么 多 的 ↲ 不 同 的 声 音 ↲ 在 ↲ 这 里 ↲ 也 将 出 现 ↲ 多 少 次 ↲ 长 长 的 ↲ ↲ 恢 复 原 来 的 ↲ 声 音 ↲↲ 从 一 个 梦 里 ↲ 调 的 汽 车 ↲ 古 老 的 城 市 ↲ — — 古 老 的 城 市 ↲ 交 谈 的 声 音 ↲ 是 两 个 ↲ 在 中 国 的 田 野 上'}]\n",
       " {'generated_text': '没有人理解荷马的摇篮，↲没有人从拐角的墙壁，↲ 要 不 要 提 到 一 个 屋 顶 。 ↲ 没 有 人 要 做 的 人 去 ， ↲ 着 一 个 不 小 心 翼 翼 的 脚 步 ， ↲ 让 屋 子 里 的 风 向 ， ↲ 让 屋 里 和 我 们 在 屋 顶 里 走 动 ， ↲ 我 们 要 把 你 们 和 屋 顶 ， ↲ 进 了 我 们 这 样 的 就 是 不 能 发 出 的 ； ↲ 我 们 的 欢 乐 与 泪 河 一 起 ， ↲ 着 了 一 阵 雨 ， ↲ 的 心 的 一 起 ， ↲↲ 在 这 样 的 心 的 心 的 兴 奋 类 的 心 的 大 雨 的 心 里 面 前 流 下 一 的 心 的 ， ↲ ！ ↲ ， ↲ 着 着 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 汩 小 雨 ， ↲ 的 狂 风 雨 ， ↲↲ 的 ， ↲ 里 面 的 帽 ， ↲ ， ↲ 的 大 的 心 ， ↲ 过'},\n",
       " {'generated_text': '没有人理解荷马的摇篮，↲没有人从拐角的墙壁，↲ 下 一 步 的 葬 礼 ， 向 下 探 出 深 山 的 边 缘 ， ↲ 不 知 为 什 么 ， 不 要 哭 喊 ， ↲ ，an 运 ， ↲ 因 为 它 们 已 经 忘 却 ， ↲ 在 屋 檐 下 ， ↲ 着 自 己 的 一 点 ， ↲ 永 远 不 要 向 前 走 了 ， ↲ 永 远 不 要 ， ↲ 永 远 不 要 这 样 痛 苦 。 ↲↲ 呵 ， 这 样 的 纠 缠 ， ↲ ！ 你 可 要 抓 住 我 ， 我 的 ──↲ 我 的 ！ ↲ ， ↲ 这 样 的 ！ ↲ 夜 莺 着 ， 这 样 要 在 这 样 的 不 要 不 要 把 我 要 说 ！ ↲ 你 就 在 这 样 的 不 要 在 那 ？ ↲ 我 不 要 我 ？ ↲ 一 乃 然 ， 不 要 把 我 的 ！ ↲ 风 吹 吧 ， 不 要 ↲ ， 不 要 紧 ， ↲ 在 我 的 不 要 不 要 不 要 诉 ， 不 要 是 这 样 的 是 ， 不 要 把 我 的 山 的 乌 鸦 雀 的 ？ ↲ute 这 样 的 ， ↲ 一 切 不'},\n",
       " {'generated_text': '没有人理解荷马的摇篮，↲没有人从拐角的墙壁，↲ 着 园 丁 的 步 伐 。 ↲↲ 风 吹 过 ， 越 来 越 清 澈 ， ↲ 山 风 的 园 林 就 要 燃 起 了 ↲ 垂 下 了 ， 平 原 的 平 原 ； ↲ 古 墙 围 着 了 一 个 古 老 的 梦 ； ↲ 着 河 底 的 乌 龟 ， ↲ 这 些 翠 绿 的 淡 水 的 翠 绿 ， ↲ 着 我 的 心 肠 ； ↲ 的 这 满 的 乌 云 ， ↲ 得 放 下 没 有 人 的 熟 练 。 ↲ ， ↲ 的 满 了 一 条 底 要 了 。 ↲ 我 的 山 的 情 ， ↲ 。 ↲ 名 ， 这 么 慢 慢 慢 慢 的 满 园 的 山 的 山 ， ↲ 的 晚 风 的 山 坡 的 露 的 熟 的 话 ； ↲ 的 一 天 上 一 天 的 山 峦 ， ↲ 的 山 的 山 的 黄 昏 黄 金 黄 昏 黄 昏 黄 昏 黄 金 黄 金 ↲ ， ↲ 。 ↲ 我 的 波 ； ↲ ； ↲ 的 ， ↲ 我 的 一 下 了 。 ↲ ； ↲ ； ↲ ； ↲ ，'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generator(\"在各自的↲不同的象限里↲我看到生活↲总有一种↲与众不同的↲\", max_length=256, do_sample=True, top_k=5, top_p=0.9, num_return_sequences=3, use_cache=True,)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进 来 吧 ， 让 赌 局 再 持 久 些 吧 ！ ↲\n",
    "我 们 将 带 来 史 诗 般 的 消 息 ， 一 个 巨 大 的 ↲\n",
    "惊 人 的 坠 落 ， 颠 覆 的 记 录 ； ↲\n",
    "一 段 反 复 出 现 的 的 故 事 ， ↲\n",
    "在 一 个 新 的 空 间 里 进 行 着 ↲\n",
    "一 连 串 的 厄 运 ，↲\n",
    "在 每 一 个 的 路 口 ， 都 有 人 犯 罪 。↲ \n",
    "他 们 在 各 自 的 ↲ \n",
    "不 同 的 象 限 里 ↲ \n",
    "制 造 着 不 同 的 心 理 ，↲\n",
    "做 着 不 同 的 梦 。 ↲↲ \n",
    "\n",
    "\n",
    "我 听 过 那 些 吵 吵 嚷 嚷 的 分 裂 ↲ 使 我 产 生 了 一 种 倾 向 ， ↲ 我 认 为 那 是 一 种 欺 骗 ， ↲ 象 一 些 人 散 发 出 的 言 词 ↲ 使 我 产 生 了 漠 视 ， \n",
    "\n",
    "'在各自的↲不同的象限里↲ 我 迎 来 我 自 己 ↲ 我 分 别 是 一 颗 梨 、 糖 梨 、 乳 房 和 蝴 蝶 ↲\n",
    "\n",
    "谁 的 手 杖 敲 响 ， 谁 的 头 颅 沉 入 黑 暗 ？↲↲\n",
    "\n",
    "在 这 个 深 夜 ， 我 将 歌 唱 生 命 中 的 四 月 ↲\n",
    "无 边 的 黑 色 的 火 焰 ， 无 尽 的 黑 色 的 火 焰 ↲ \n",
    "我 将 在 你 的 眼 睛 里 消 失 ↲ \n",
    "在 那 的 黑 色 的 ，黑 色 的 火 焰 中 ↲ \n",
    "在 那 无 尽 的 黑 色 的 火 焰 中 ↲ 我 的 头 颅 沉 入 黑 暗 ↲↲\n",
    "黄河啊！原始的水！原始的阴影，↲\n",
    "这粗糙的血酒！可怜的人间，不能如此，↲\n",
    "不能如此忘忧，↲\n",
    "在这世界中央，↲\n",
    "人们的心上人儿烟火般的过去。↲↲\n",
    "\n",
    "这里是人们的丑陋的居处，↲\n",
    "这里是良知的最后的原野，↲\n",
    "在这里，成熟的人们在世俗的哭泣里，↲\n",
    "在无知的哭泣里放下一个灵魂的位置，↲\n",
    "在这里，我们的忙碌和谐的腿骨上，↲\n",
    "没有上帝。\n",
    "\n",
    "生命会自己进入↲\n",
    "下一个浅浅的冬天。↲↲\n",
    "\n",
    "而痛苦是不可穷究的。↲↲\n",
    "\n",
    "只是，↲\n",
    "一个人，在不可知的世界里，↲\n",
    "对一切的不可窥之魔，↲\n",
    "我的潦倒竟不能自主。↲↲\n",
    "\n",
    "夜半天空，↲\n",
    "我等我的睡眠，↲\n",
    "和一块滚石，↲\n",
    "和我的童年。↲↲\n",
    "\n",
    "没有人理解荷马的摇篮，↲没有人从拐角的墙壁，↲\n",
    "\n",
    "我 记 得 我 的 童 年 ， ↲ 我 记 得 我 是 那 棵 树 。 ↲ 我 记 得 我 的 任 何 时 候 ， ↲ 我 记 得 我 们 的 爱 情 ， ↲ 我 的 任 性 的 保 姆 ， ↲\n",
    "\n",
    "祖国低矮的山岩，↲低矮的，\n",
    "这 里 是 良 知 的 的 方 向 ， ↲ 四 顾 的 虐 待 ， ↲ 的 是 罪 的 ， ↲ 在 无 尽 的 传 说 里 ， ↲ 替 了 灰 尘 的 网 页 ；\n",
    "充 斥 着 活 人 的 金 钱 ；↲ 我 要 截 住 的 野 花 ， ↲ 要 求 着 我 的 这 些 刺 骨 的 欢 欣 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, GPT2LMHeadModel, TextGenerationPipeline\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"uer/gpt2-chinese-lyric\")\n",
    "# model = GPT2LMHeadModel.from_pretrained(\"uer/gpt2-chinese-lyric\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"/home/jaj/workspace/UER-py/myspace/sanwen\")\n",
    "model = GPT2LMHeadModel.from_pretrained('/home/jaj/workspace/UER-py/myspace/sanwen')\n",
    "text_generator = TextGenerationPipeline(model, tokenizer)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '一 千 朵 雪 落 无 声 ↲ 我 把 日 子 铸 成 它 ↲ 填 进 泥 土 ↲ 填 满 一 个 < 自 己 的 日 子 ↲ 像 一 只 收 集 病 菌 的 老 鼠 ↲ 播 种 革 命 的 火 种 ， 掉 弄 灵 巧 的 概 念 ↲ 将 王 宫 搞 得 惴 惴 不 安 ↲ 他 兴 奋 他 战 栗 他 表 皮 敏 感 ↲ 自 恋 得 发 狂 自 画 像 就 画 了 四 五 张 ↲ 得 意 的 表 达 ↲ 他 在 摇 撼 他 想 写 的 就 是 想 象 ↲ 西 的 那 条 河 上 的 天 边 ↲ 着 他 ↲ ， 他 的 时 间 ↲ 他 的 花 园 已 是 他 的 脸 像 他 的 天 气 ， 仿 佛 是 一 天 的 ↲ ， 他 的 天 上 ， 他 的 向 他 的 天 ↲ 但 的 ， 不 是 一 生 活 的 是 不 得 的 人 的 ↲ 他 的 他 的 床 边 上 ， 他 ， 他 的 轮 ↲ 不 滚 滚 动 的 水 的 嘴 ， 逐 渐 渐 渐 渐 渐 渐 渐 渐 渐 明 天 上 的 ↲ 他 的 变 成 为 ↲ 不 是 一 生 命 运 到 他 的 说 ， 向 上 ， 像 中 的 ， 向 ↲ ，'},\n",
       " {'generated_text': '一 千 朵 雪 落 无 声 ↲ 我 把 日 子 铸 成 它 ↲ 填 进 泥 土 ↲↲ 我 不 再 是 水 ， 是 树 ↲ 在 日 蚀 的 草 丛 中 ↲ 我 不 在 乎 它 们 是 我 ↲ 在 我 生 日 的 时 候 遇 见 它 ↲ 通 而 来 的 一 种 无 声 的 表 情 ↲ 着 夜 空 ↲ 我 在 一 瞬 间 ↲↲ 这 是 我 的 生 命 ↲ 我 开 始 平 静 而 舒 缓 ↲ 这 是 我 生 命 中 的 生 命 ↲ 我 不 满 意 所 有 过 路 人 ↲ 着 他 们 的 偶 像 ↲ ↲ 于 我 的 笑 ↲↲ 我 的 树 ↲ 我 的 我 的 宽 阔 遇 到 来 感 觉 察 看 我 的 ↲ 我 的 面 前 行 走 了 我 的 舞 足 ↲ 我 的 错 误 我 的 我 ↲ 我 的 眼 睛 ↲↲ 我 的 悲 哀 伤 害 我 ↲ 使 我 的 楚 ↲ 痛 楚 ↲ 他 们 ， 他 们 ↲ 我 的 悲 哀 伤 害 了 ↲ 我 的 我 ↲ 我 ↲ 我 的 心 事 ↲ 我 的 雨 、 我 ↲ 我 的 玻 璃 ↲ 我 的 ↲ 我 自 行 列 复 杂 的 ↲ 我 ↲ 我 ↲↲ 我 ↲↲ 我'},\n",
       " {'generated_text': '一 千 朵 雪 落 无 声 ↲ 我 把 日 子 铸 成 它 ↲ 填 进 泥 土 ↲ 填 满 一 个 < 亲 近 小 屋 ↲↲ 废 的 日 子 ↲ 像 一 堆 无 知 的 树 ↲ 浓 雾 裹 住 我 的 门 ↲↲ 我 的 四 周 ↲ 被 春 风 遗 忘 着 ↲ 出 我 的 双 手 ↲↲ 伤 口 ， 偷 偷 ↲ 我 的 声 音 被 你 伤 痛 ↲ 我 被 你 的 带 领 ↲ 震 撼 浓 云 ↲↲ 我 不 能 痛 饮 ↲ 那 不 能 抵 抗 的 ↲ ↲ 的 ↲↲ 尖 的 雪 ↲ 的 ↲ ↲ 如 ↲ ↲ 满 床 ↲ 星 ↲ 如 ↲ 一 个 ↲ 星 星 ↲ 然 ↲ ↲ ↲ ↲ 我 ↲ 的 ↲ 星 ↲ 不 醒 ↲ ↲ 说 ↲ 奔 跑 ↲ 掠 过 ↲ 我 ↲ ↲ 我 的 ↲ ↲ 星 ↲ ↲ ↲ 星 星 ↲ 我 ↲ ↲ ↲ ↲ 掠 ↲ 我 的 不 能 ↲ 我 ↲ 古 劫 持 续 的 ↲ 我 ↲ ↲ 星 ↲ 星 星 星 星 ↲ 我 的 ↲ 我 ↲ ↲ 我 ↲ 我 的 ↲ ↲ 我 ↲ 星 ↲ ↲ 星 星 星'}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generator(\"一 千 朵 雪 落 无 声 ↲ 我 把 日 子 铸 成 它 ↲ 填 进 泥 土 ↲\", max_length=256, do_sample=True,top_k=5, top_p=0.95, num_return_sequences=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[{'generated_text': '梅花落满了南山 ↲ 啊 ， 多 少 人 看 多 了 江 南 阴 冷 ↲↲ 这 个 月 我 多 么 渴 望 能 够 ↲ 当 我 看 到 你 开 花 了 ↲ 你 的 日 子 正 变 成 一 条 金 色 的 小 河 ↲ 这 是 我 对 你 无 言 的 流 向 ↲ 西 的 这 块 麦 田 ↲↲ 这 是 你 的 灵 魂 ↲ 你 手 里 紧 握 着 麦 穗 ↲ 你 含 泪 的 彩 色 ↲ 肯 定 留 下 我 在 这 里 ↲ 入 我 的 眼 睛 ↲↲ 尖 的 树 林 ↲ 一 切 ↲ 我 ↲ ↲ 我 的 持 你 ， 4 笑 ↲ 我 ↲ 我 ↲ 我 ↲ 裂 ↲↲ 我 的 ↲ 古 树 冠 冕 ↲ 我 ↲ 我 的 热 ↲ 我 ↲ 我 的 小 话 ↲ 我 的 ↲ ↲ 我 的 ↲ ↲ 我 的 窗 ↲ 鱼 宫 殿 堂 的 人 的 小 事 ↲ 我 ↲ 我 站 在 泥 土 摇 晃 动 ， 我 ↲ 一 道 路 上 ↲ 我 ↲ 我 的 人 ↲ 我 ↲ 我 的 小 宫 殿 堂 ↲ ↲ 我 ， ↲ 我 ↲ 我 的 心 事 ↲↲ 叶 荫 的 心 ↲ 的 ↲ 我'},\n",
    " {'generated_text': '梅花落满了南山 ↲ 一 千 年 的 寒 风 ↲↲ 七 月 ， 那 人 来 得 满 园 子 的 一 生 ↲ 定 在 谷 外 拋 锚 的 花 园 围 栏 ↲↲ 我 看 见 你 长 大 了 饥 饿 的 名 字 ↲ 一 下 ， 你 的 名 字 在 山 谷 ↲ 仿 佛 一 粒 黏 星 ↲↲ 我 穿 著 绿 洲 的 草 坡 ↲ 又 一 坡 的 寂 寞 ↲ 金 黄 的 手 指 插 满 了 风 ↲↲ 我 的 心 情 ↲ 我 要 贴 着 白 沙 的 青 苔 ↲ 贴 到 蓝 色 的 胸 膛 ↲ ↲ ↲ 绒 上 ↲ 我 的 床 ↲ 我 的 心 灵 魂 魄 ↲ 上 游 荡 的 柔 和 你 的 天 空 气 息 虚 伪 装 饰 ↲↲ 午 睡 梦 的 浊 的 心 ↲ 我 的 心 ↲ 我 的 床 边 ↲ 络 时 候 鸟 ↲ 的 心 ↲ 的 日 子 里 ， ↲ 让 我 的 日 子 的 心 的 日 子 上 ↲↲ 我 ↲↲ 我 的 ↲↲ 的 早 晨 曦 ↲ 黄 昏 暗 绿 ↲↲ 尖 锐 利 的 阳 光 焰 ↲ 面 ↲ 全 部 分 ↲ 让 我 日 子 的 心 里 ，'},\n",
    " {'generated_text': '梅花落满了南山 ↲↲ 冬 日 的 雨 下 在 江 湖 ↲ 江 湖 注 定 是 你 诗 中 的 一 个 险 句 ↲↲ 不 如 学 仙 去 ↲ 无 端 端 的 你 ↲ 不 能 不 去 ↲↲ 你 是 我 的 好 友 ↲ 你 是 我 的 朋 友 ↲ 我 们 是 你 的 兄 弟 ↲ 你 是 我 的 朋 友 ↲ 永 远 在 你 的 心 里 ↲ 你 是 一 首 诗 ↲↲ 你 是 一 朵 看 到 的 ↲ 你 的 眼 睛 ↲ 永 不 用 的 思 想 ↲ 永 不 长 的 ↲↲ 你 来 了 ↲ ↲ ↲ 的 ↲ ↲ ↲ 你 的 ↲ 哪 一 巴 ↲ 一 滴 ↲ 哪 一 个 ↲ ↲ 我 的 ↲ ↲ 我 ↲ 船 ↲ ↲ ↲ 我 ↲ 你 走 ↲ 到 你 的 ↲ 你 走 了 ↲ 你 ↲ 我 的 ↲ 的 ↲ 你 的 ↲ 我 的 你 的 ↲ ↲ ↲ ↲ ↲ ↲ ↲ 的 ↲ 你 的 ↲ ↲ 掠 价 ↲ 掠 过 ↲ 你 的 ↲ 你 掠 过 ↲ ↲ 我 的 ↲ ↲ 我 ↲ ↲ ↲ ↲ ↲ 你 的 ↲ 于 忧 愁 ↲'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[{'generated_text': '夜空中最亮的星， 这 是 爱 ， 就 此 一 生 ， 愿 我 的 我 的 吻 ， 一 再 爱 ， 也 许 是 我 真 ， 想 对 你 ， 狂 妄 代 价 ， 会 些 为 了 ， 这 种 罪 ， 我 爱 你 ， 没 有 未 能 令 我 的 手 ， 嗯 。 ， 不 要 独 立 生 活 下 也 记 忆 为 我 们 的 心 恼 ， 明 天 可 躲 ， 当 我 的 我 这 单 车 ， 失'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '{冬}<3>[梅花,雪,寒冷,思念]梅花落满了南山，像一地的雪， ， ， ， 一 样 。 ， 的 海 滩 的 小 草 滩 ， ， ， 还 是 得 很 早 年 的 ， 在 海 洋 的 的 人 类 似 的 时 间 的 尽 头 ， 。 ， ， 的 得 很 远 方 ， 我 的 的 一 个 时 候 。 ， 地 上'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generator(\"\\{冬\\}<>[梅花,雪,寒冷,思念]梅花落满了南山，像一地的雪，\", max_length=128, do_sample=True,top_k=5, top_p=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator(\"最美的不是下雨天，是曾与你躲过雨的屋檐\", max_length=256, do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaj/miniconda3/envs/uer/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Can't load tokenizer for '/localdata/workspace/UER-py/models/clyric'. Make sure that:\n\n- '/localdata/workspace/UER-py/models/clyric' is a correct model identifier listed on 'https://huggingface.co/models'\n\n- or '/localdata/workspace/UER-py/models/clyric' is the correct path to a directory containing relevant tokenizer files\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m BertTokenizer, GPT2LMHeadModel, TextGenerationPipeline\n\u001b[1;32m      2\u001b[0m \u001b[39m# tokenizer = BertTokenizer.from_pretrained(\"uer/gpt2-chinese-lyric\")\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# model = GPT2LMHeadModel.from_pretrained(\"uer/gpt2-chinese-lyric\")\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m tokenizer \u001b[39m=\u001b[39m BertTokenizer\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39m/localdata/workspace/UER-py/models/clyric\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      5\u001b[0m model \u001b[39m=\u001b[39m GPT2LMHeadModel\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m'\u001b[39m\u001b[39m/localdata/workspace/UER-py/models/clyric\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m text_generator \u001b[39m=\u001b[39m TextGenerationPipeline(model, tokenizer)\n",
      "File \u001b[0;32m~/miniconda3/envs/uer/lib/python3.8/site-packages/transformers-4.6.1-py3.8.egg/transformers/tokenization_utils_base.py:1708\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(full_file_name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m full_file_name \u001b[39min\u001b[39;00m resolved_vocab_files\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m   1703\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[1;32m   1704\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt load tokenizer for \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. Make sure that:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1705\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m- \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is a correct model identifier listed on \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1706\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m- or \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is the correct path to a directory containing relevant tokenizer files\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1707\u001b[0m     )\n\u001b[0;32m-> 1708\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(msg)\n\u001b[1;32m   1710\u001b[0m \u001b[39mfor\u001b[39;00m file_id, file_path \u001b[39min\u001b[39;00m vocab_files\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   1711\u001b[0m     \u001b[39mif\u001b[39;00m file_id \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m resolved_vocab_files:\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for '/localdata/workspace/UER-py/models/clyric'. Make sure that:\n\n- '/localdata/workspace/UER-py/models/clyric' is a correct model identifier listed on 'https://huggingface.co/models'\n\n- or '/localdata/workspace/UER-py/models/clyric' is the correct path to a directory containing relevant tokenizer files\n\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, GPT2LMHeadModel, TextGenerationPipeline\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"uer/gpt2-chinese-lyric\")\n",
    "# model = GPT2LMHeadModel.from_pretrained(\"uer/gpt2-chinese-lyric\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"/localdata/workspace/UER-py/models/clyric\")\n",
    "model = GPT2LMHeadModel.from_pretrained('/localdata/workspace/UER-py/models/clyric')\n",
    "text_generator = TextGenerationPipeline(model, tokenizer)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " [{'generated_text': '最美的不是下雨天，是曾与你躲过雨的屋檐 ， 下 课 铃 声 响 起 的 瞬 间 ， 我 们 的 笑 脸 ， 有 太 多 回 忆 在 浮 现 ， 是 你 总 在 我 身 边 ， 不 知 道 会 不 会 再 见 ， 从 现 在 开 始 到 永 远 ， 想 说 的 语 言 凝 结 成 一 句 ， 不 管 我 们 是 否 能 够 兑 现 ， 想 说 的 语 言 凝 结'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaj/miniconda3/envs/uer/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLNetTokenizer, GPT2LMHeadModel\n",
    "from transformers import TextGenerationPipeline\n",
    "import jieba\n",
    "# add spicel process \n",
    "class XLNetTokenizer(XLNetTokenizer):\n",
    "    translator = str.maketrans(\" \\n\", \"\\u2582\\u2583\")\n",
    "    def _tokenize(self, text, *args, **kwargs):\n",
    "        text = [x.translate(self.translator) for x in jieba.cut(text, cut_all=False)]\n",
    "        text = \" \".join(text)\n",
    "        return super()._tokenize(text, *args, **kwargs)\n",
    "    def _decode(self, *args, **kwargs):\n",
    "        text = super()._decode(*args, **kwargs)\n",
    "        text = text.replace(' ', '').replace('\\u2582', ' ').replace('\\u2583', '↲')\n",
    "        return text\n",
    "\n",
    "tokenizer = XLNetTokenizer.from_pretrained('/home/jaj/workspace/UER-py/models/cpm')\n",
    "model = GPT2LMHeadModel.from_pretrained(\"/home/jaj/workspace/UER-py/models/cpm\")\n",
    "\n",
    "text_generater = TextGenerationPipeline(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '不如学仙去,↲萝歌坐到一曲然后走人。↲'},\n",
       " {'generated_text': '不如学仙去,↲萝歌舞腰,拨动裤管上的红尘↲调一曲轻盈之月夜之歌↲不拘小节地进入梦乡↲像寄生在蟋蟀声中的害虫↲悄悄爬出铁轨间密谋的笼子↲'},\n",
       " {'generated_text': '不如学仙去,↲萝歌坐到一曲琴音里......↲'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generater(\"不如学仙去,↲\", max_length=256, do_sample=True, use_cache=True, top_p=0.8, repetition_penalty=1.1,num_return_sequences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Title: '语言' Topic: '哲思' Keywords: '语言,诗歌,上帝,无穷,蓝色' Content: 语言是一种可用来赞美的品质。↲↲有人专门收集世间的唯美谎言,↲并将它们再版,无数次被推翻。↲↲但最终被践约的却是语言自己。↲↲语言是律法,顺应了坚固的壁垒,↲它把贞洁的和美丽的都割走,↲留下铿锵的声音,花朵和花香。↲↲语言是律法,顺应了坚固的壁垒,↲它把贞洁和美丽的都割走,↲\"},\n",
       " {'generated_text': \"Title: '语言' Topic: '哲思' Keywords: '语言,诗歌,上帝,无穷,蓝色' Content: 语言就是飞翔↲就是语言的纯粹与反复。↲↲语言就是飞翔↲就是语言自己的手掌↲在石头和铁的捶打下↲发出咔咔的响声↲就是声音↲↲语言就是飞翔↲就是语言自己的手掌↲在石头和铁的捶打下↲发出咔咔的响声↲↲语言就是飞翔↲就是语言自己的手掌↲在石头和铁的捶打下↲发出咔咔的响声↲\"},\n",
       " {'generated_text': \"Title: '语言' Topic: '哲思' Keywords: '语言,诗歌,上帝,无穷,蓝色' Content: 语言是↲世界的赠品↲↲在这个世界上↲语言是无用的↲↲一种语言↲在这个世界上↲是没有门的↲↲一种语言↲在这个世界上↲是没有窗的↲↲一种语言↲\"}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generater(\"Title: '语言' Topic: '哲思' Keywords: '语言,诗歌,上帝,无穷,蓝色' Content:\", max_length=256, do_sample=True, use_cache=True, top_p=0.8, top_k=5, num_return_sequences=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49a4d35495a0ee52f35720c27c94986b4a3077a71a8c6157808376aed5c51fad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
