{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, GPT2LMHeadModel, TextGenerationPipeline\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"uer/gpt2-chinese-lyric\")\n",
    "# model = GPT2LMHeadModel.from_pretrained(\"uer/gpt2-chinese-lyric\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"/home/jaj/workspace/UER-py/models/sanwen\")\n",
    "model = GPT2LMHeadModel.from_pretrained('/home/jaj/workspace/UER-py/models/sanwen')\n",
    "text_generator = TextGenerationPipeline(model, tokenizer)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '梅花开在南山上， 我 们 听 到 地 的 叫 喊 地 上 ， 从 我 们 的 到 来 一 声 音 ！ ， 说 ， 到 学 校 在 你 生 活 过 往 下 ， 他 们 的 小 说 地 方 向 着 ， 是 人 是 我 也 为 了 什 么 可 以 前 途 径 径 来 。 只 是 多 么 ？ 下 去 了 ， 不 要 ， 这 一 口 可 见 过 去 地 看 见 到 下 ， 我 的 声 音 乐 时 候 久 以 及 其 时 候 ， 一 把 它 的 花 又 一 支 了 的 家 中 央 ， 地 相 似 的 叫 见 过 来 年 ， 你 也 回 来 ， 可 以 归 宿 命 到 过 去 。 ， 为 什 么 也 好 出 来 去 也 在 山 神 秘 密 复 着 梦 想 起 头 ， 我 们 的 穿 越 发 还 在 电 视 线 路 上 等 待 电 肯 肯 开 了 下 ， 到 来 的 。 。 什 么 要 的 地 声 ， 什 么 ， 使 它 的 音 走 过 去 了 。 ， 可 爱 人 的 刀 消 了 一 个'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generator(\"梅花开在南山上，\", max_length=256, do_sample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[{'generated_text': '夜空中最亮的星， 这 是 爱 ， 就 此 一 生 ， 愿 我 的 我 的 吻 ， 一 再 爱 ， 也 许 是 我 真 ， 想 对 你 ， 狂 妄 代 价 ， 会 些 为 了 ， 这 种 罪 ， 我 爱 你 ， 没 有 未 能 令 我 的 手 ， 嗯 。 ， 不 要 独 立 生 活 下 也 记 忆 为 我 们 的 心 恼 ， 明 天 可 躲 ， 当 我 的 我 这 单 车 ， 失'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator(\"最美的不是下雨天，是曾与你躲过雨的屋檐\", max_length=256, do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator(\"当两颗心开始震动,当你瞳孔学会闪躲\", max_length=100, do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator(\"当 两 颗 心 开 始 震 动 \", max_length=100, do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator(\"当两颗心开始震动，\", max_length=100, do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, GPT2LMHeadModel, TextGenerationPipeline\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"uer/gpt2-chinese-lyric\")\n",
    "# model = GPT2LMHeadModel.from_pretrained(\"uer/gpt2-chinese-lyric\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"/localdata/workspace/UER-py/models/clyric\")\n",
    "model = GPT2LMHeadModel.from_pretrained('/localdata/workspace/UER-py/models/clyric')\n",
    "text_generator = TextGenerationPipeline(model, tokenizer)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " [{'generated_text': '最美的不是下雨天，是曾与你躲过雨的屋檐 ， 下 课 铃 声 响 起 的 瞬 间 ， 我 们 的 笑 脸 ， 有 太 多 回 忆 在 浮 现 ， 是 你 总 在 我 身 边 ， 不 知 道 会 不 会 再 见 ， 从 现 在 开 始 到 永 远 ， 想 说 的 语 言 凝 结 成 一 句 ， 不 管 我 们 是 否 能 够 兑 现 ， 想 说 的 语 言 凝 结'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaj/miniconda3/envs/uer/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading: 100%|██████████| 713k/713k [00:01<00:00, 676kB/s]  \n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nTFGPT2LMHeadModel requires the TensorFlow library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://www.tensorflow.org/install and follow the ones that match your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[39mreturn\u001b[39;00m text\n\u001b[1;32m     16\u001b[0m tokenizer \u001b[39m=\u001b[39m XLNetTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m'\u001b[39m\u001b[39mmymusise/CPM-Generate-distill\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m model \u001b[39m=\u001b[39m TFGPT2LMHeadModel\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mmymusise/CPM-Generate-distill\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     19\u001b[0m text_generater \u001b[39m=\u001b[39m TextGenerationPipeline(model, tokenizer)\n\u001b[1;32m     21\u001b[0m \u001b[39mprint\u001b[39m(text_generater(\u001b[39m\"\u001b[39m\u001b[39m天下熙熙，\u001b[39m\u001b[39m\"\u001b[39m, max_length\u001b[39m=\u001b[39m\u001b[39m15\u001b[39m, top_k\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, use_cache\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, prefix\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/uer/lib/python3.8/site-packages/transformers-4.6.1-py3.8.egg/transformers/utils/dummy_tf_objects.py:955\u001b[0m, in \u001b[0;36mTFGPT2LMHeadModel.from_pretrained\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    954\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_pretrained\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 955\u001b[0m     requires_backends(\u001b[39mself\u001b[39;49m, [\u001b[39m\"\u001b[39;49m\u001b[39mtf\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "File \u001b[0;32m~/miniconda3/envs/uer/lib/python3.8/site-packages/transformers-4.6.1-py3.8.egg/transformers/file_utils.py:569\u001b[0m, in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m    567\u001b[0m name \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    568\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(BACKENDS_MAPPING[backend][\u001b[39m0\u001b[39m]() \u001b[39mfor\u001b[39;00m backend \u001b[39min\u001b[39;00m backends):\n\u001b[0;32m--> 569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([BACKENDS_MAPPING[backend][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mformat(name) \u001b[39mfor\u001b[39;00m backend \u001b[39min\u001b[39;00m backends]))\n",
      "\u001b[0;31mImportError\u001b[0m: \nTFGPT2LMHeadModel requires the TensorFlow library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://www.tensorflow.org/install and follow the ones that match your environment.\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLNetTokenizer, GPT2LMHeadModel\n",
    "from transformers import TextGenerationPipeline\n",
    "import jieba\n",
    "# add spicel process \n",
    "class XLNetTokenizer(XLNetTokenizer):\n",
    "    translator = str.maketrans(\" \\n\", \"\\u2582\\u2583\")\n",
    "    def _tokenize(self, text, *args, **kwargs):\n",
    "        text = [x.translate(self.translator) for x in jieba.cut(text, cut_all=False)]\n",
    "        text = \" \".join(text)\n",
    "        return super()._tokenize(text, *args, **kwargs)\n",
    "    def _decode(self, *args, **kwargs):\n",
    "        text = super()._decode(*args, **kwargs)\n",
    "        text = text.replace(' ', '').replace('\\u2582', ' ').replace('\\u2583', '\\n')\n",
    "        return text\n",
    "\n",
    "tokenizer = XLNetTokenizer.from_pretrained('mymusise/CPM-Generate-distill')\n",
    "model = GPT2LMHeadModel.from_pretrained(\"mymusise/CPM-Generate-distill\")\n",
    "\n",
    "text_generater = TextGenerationPipeline(model, tokenizer)\n",
    "\n",
    "print(text_generater(\"天下熙熙，\", max_length=15, top_k=1, use_cache=True, prefix=''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator('梅花开在南山上，', max_length=50, do_sample=True, top_p=0.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 | packaged by conda-forge | (default, Nov 22 2022, 08:49:35) \n[GCC 10.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc929b8184b97e264f70f5284f280b8cccade275b07b2944f5e202851ce07696"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
