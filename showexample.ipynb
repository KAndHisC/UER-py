{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, GPT2LMHeadModel, TextGenerationPipeline\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"uer/gpt2-chinese-lyric\")\n",
    "# model = GPT2LMHeadModel.from_pretrained(\"uer/gpt2-chinese-lyric\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"models/clue\")\n",
    "model = GPT2LMHeadModel.from_pretrained('models/clue')\n",
    "text_generator = TextGenerationPipeline(model, tokenizer)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '在各自的↲不同的象限里↲我看到生活↲总有一种↲与众不同的↲ 与 众 不 同 的 ↲ 与 众 不 同 的 ↲↲ 啊 ↲ 最 终 有 一 天 ↲ 我 也 不 得 不 ↲ 在 我 后 面 ↲ 跟 一 个 陌 生 人 说 话 ↲ 他 就 是 那 个 ↲ 唱 着 歌 来 的 ↲ 唱 着 歌 来 的 ↲ 他 就 开 始 变 得 ↲ 其 实 ↲ 一 直 就 是 ↲ 一 直 到 ↲ 我 不 再 想 说 的 ↲ 也 不 再 想 说 ↲↲ 就 是 结 婚 以 后 ↲ 你 就 出 来 了 ↲ 一 个 人 ↲ 一 个 人 ↲ 在 酒 馆 里 ↲ 喝 着 茶 ↲ 聊 着 天 ↲↲ 我 就 出 来 了 ↲ 象 你 一 样 ↲ 看 着 我 ↲ 开 始 ↲ 以 来 ↲ 就 是 一 件 事 情 ↲ 桌 子 ↲ 空 着 ↲↲ ↲ ↲ ↲ ↲ ↲ ↲ ↲ ↲ ↲ ↲ 一 切 ↲ 话 ↲ ↲ ↲ ↲ ↲ ↲ 一 切 ↲ — — — —'},\n",
       " {'generated_text': '在各自的↲不同的象限里↲我看到生活↲总有一种↲与众不同的↲ 与 众 不 同 的 ↲ 与 众 不 同 的 ↲ 与 众 不 同 的 ↲↲ 在 这 里 ↲ 最 终 的 情 感 ↲ 就 是 诗 ↲ 所 体 现 的 ↲ 最 真 的 ↲ 也 是 最 美 的 ↲ 万 物 的 本 质 ↲ 都 是 为 死 而 生 的 ↲ 他 们 都 在 这 里 ↲ 死 去 ↲ 不 死 ↲ 不 死 ↲ 也 没 有 灵 魂 ↲↲ 我 ↲ 只 好 紧 紧 ↲ 抱 着 这 一 切 ↲ 我 四 处 寻 找 ↲ 找 到 一 个 名 字 ↲ 名 字 叫 做 ↲ 故 乡 ↲ 故 乡 ↲ 的 一 切 ↲ 我 在 这 里 ↲↲ 我 们 就 要 分 手 ↲ 在 这 里 ↲ 就 要 分 手 ↲ 在 这 里 ↲ 在 这 里 ↲ 又 是 一 个 ↲ 又 是 一 个 ↲ 又 是 一 个 ↲ ↲ ↲ 那 天 ↲ 有 人 破 晓 ↲ 什 么 也 没 有 破 晓 ↲ 什 么 也 没 破 晓 ↲ — — ↲ 呵 ↲'},\n",
       " {'generated_text': '在各自的↲不同的象限里↲我看到生活↲总有一种↲与众不同的↲ 与 众 不 同 的 ↲ 与 众 不 同 的 ↲↲ 在 这 里 ↲ 是 一 片 ↲ 辽 阔 的 大 海 ↲ 和 大 河 ↲ 我 想 ↲ 在 这 里 ↲ 会 和 许 多 人 分 享 ↲ 生 活 的 闪 耀 ↲ 以 及 ↲ 生 活 中 ↲ 所 遇 到 的 一 些 ↲ 无 法 解 释 的 问 题 ↲↲ 在 这 里 ↲ 也 会 出 现 ↲ 无 法 解 释 的 问 题 ↲ 我 想 ↲ 在 这 里 ↲ 也 会 出 现 ↲ 多 少 次 ↲ 我 自 己 ↲ 也 不 知 道 ↲ 是 出 于 什 么 原 因 ↲ 在 这 里 ↲ 会 出 现 ↲ 这 么 多 的 ↲ 不 同 的 声 音 ↲ 在 ↲ 这 里 ↲ 也 将 出 现 ↲ 多 少 次 ↲ 长 长 的 ↲ ↲ 恢 复 原 来 的 ↲ 声 音 ↲↲ 从 一 个 梦 里 ↲ 调 的 汽 车 ↲ 古 老 的 城 市 ↲ — — 古 老 的 城 市 ↲ 交 谈 的 声 音 ↲ 是 两 个 ↲ 在 中 国 的 田 野 上'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generator(\"在各自的↲不同的象限里↲我看到生活↲总有一种↲与众不同的↲\", max_length=256, do_sample=True, top_k=5, top_p=0.9, num_return_sequences=3, use_cache=True,)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进 来 吧 ， 让 赌 局 再 持 久 些 吧 ！ ↲\n",
    "我 们 将 带 来 史 诗 般 的 消 息 ， 一 个 巨 大 的 ↲\n",
    "惊 人 的 坠 落 ， 颠 覆 的 记 录 ； ↲\n",
    "一 段 反 复 出 现 的 的 故 事 ， ↲\n",
    "在 一 个 新 的 空 间 里 进 行 着 ↲\n",
    "一 连 串 的 厄 运 ，↲\n",
    "在 每 一 个 的 路 口 ， 都 有 人 犯 罪 。↲ \n",
    "他 们 在 各 自 的 ↲ \n",
    "不 同 的 象 限 里 ↲ \n",
    "制 造 着 不 同 的 心 理 ，↲\n",
    "做 着 不 同 的 梦 。 ↲↲ \n",
    "\n",
    "\n",
    "我 听 过 那 些 吵 吵 嚷 嚷 的 分 裂 ↲ 使 我 产 生 了 一 种 倾 向 ， ↲ 我 认 为 那 是 一 种 欺 骗 ， ↲ 象 一 些 人 散 发 出 的 言 词 ↲ 使 我 产 生 了 漠 视 ， \n",
    "\n",
    "'在各自的↲不同的象限里↲ 我 迎 来 我 自 己 ↲ 我 分 别 是 一 颗 梨 、 糖 梨 、 乳 房 和 蝴 蝶 ↲\n",
    "\n",
    "谁 的 手 杖 敲 响 ， 谁 的 头 颅 沉 入 黑 暗 ？↲↲\n",
    "\n",
    "在 这 个 深 夜 ， 我 将 歌 唱 生 命 中 的 四 月 ↲\n",
    "无 边 的 黑 色 的 火 焰 ， 无 尽 的 黑 色 的 火 焰 ↲ \n",
    "我 将 在 你 的 眼 睛 里 消 失 ↲ \n",
    "在 那 的 黑 色 的 ，黑 色 的 火 焰 中 ↲ \n",
    "在 那 无 尽 的 黑 色 的 火 焰 中 ↲ 我 的 头 颅 沉 入 黑 暗 ↲↲"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, GPT2LMHeadModel, TextGenerationPipeline\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"uer/gpt2-chinese-lyric\")\n",
    "# model = GPT2LMHeadModel.from_pretrained(\"uer/gpt2-chinese-lyric\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"/home/jaj/workspace/UER-py/myspace/sanwen\")\n",
    "model = GPT2LMHeadModel.from_pretrained('/home/jaj/workspace/UER-py/myspace/sanwen')\n",
    "text_generator = TextGenerationPipeline(model, tokenizer)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '一 千 朵 雪 落 无 声 ↲ 我 把 日 子 铸 成 它 ↲ 填 进 泥 土 ↲ 填 满 一 个 < 自 己 的 日 子 ↲ 像 一 只 收 集 病 菌 的 老 鼠 ↲ 播 种 革 命 的 火 种 ， 掉 弄 灵 巧 的 概 念 ↲ 将 王 宫 搞 得 惴 惴 不 安 ↲ 他 兴 奋 他 战 栗 他 表 皮 敏 感 ↲ 自 恋 得 发 狂 自 画 像 就 画 了 四 五 张 ↲ 得 意 的 表 达 ↲ 他 在 摇 撼 他 想 写 的 就 是 想 象 ↲ 西 的 那 条 河 上 的 天 边 ↲ 着 他 ↲ ， 他 的 时 间 ↲ 他 的 花 园 已 是 他 的 脸 像 他 的 天 气 ， 仿 佛 是 一 天 的 ↲ ， 他 的 天 上 ， 他 的 向 他 的 天 ↲ 但 的 ， 不 是 一 生 活 的 是 不 得 的 人 的 ↲ 他 的 他 的 床 边 上 ， 他 ， 他 的 轮 ↲ 不 滚 滚 动 的 水 的 嘴 ， 逐 渐 渐 渐 渐 渐 渐 渐 渐 渐 明 天 上 的 ↲ 他 的 变 成 为 ↲ 不 是 一 生 命 运 到 他 的 说 ， 向 上 ， 像 中 的 ， 向 ↲ ，'},\n",
       " {'generated_text': '一 千 朵 雪 落 无 声 ↲ 我 把 日 子 铸 成 它 ↲ 填 进 泥 土 ↲↲ 我 不 再 是 水 ， 是 树 ↲ 在 日 蚀 的 草 丛 中 ↲ 我 不 在 乎 它 们 是 我 ↲ 在 我 生 日 的 时 候 遇 见 它 ↲ 通 而 来 的 一 种 无 声 的 表 情 ↲ 着 夜 空 ↲ 我 在 一 瞬 间 ↲↲ 这 是 我 的 生 命 ↲ 我 开 始 平 静 而 舒 缓 ↲ 这 是 我 生 命 中 的 生 命 ↲ 我 不 满 意 所 有 过 路 人 ↲ 着 他 们 的 偶 像 ↲ ↲ 于 我 的 笑 ↲↲ 我 的 树 ↲ 我 的 我 的 宽 阔 遇 到 来 感 觉 察 看 我 的 ↲ 我 的 面 前 行 走 了 我 的 舞 足 ↲ 我 的 错 误 我 的 我 ↲ 我 的 眼 睛 ↲↲ 我 的 悲 哀 伤 害 我 ↲ 使 我 的 楚 ↲ 痛 楚 ↲ 他 们 ， 他 们 ↲ 我 的 悲 哀 伤 害 了 ↲ 我 的 我 ↲ 我 ↲ 我 的 心 事 ↲ 我 的 雨 、 我 ↲ 我 的 玻 璃 ↲ 我 的 ↲ 我 自 行 列 复 杂 的 ↲ 我 ↲ 我 ↲↲ 我 ↲↲ 我'},\n",
       " {'generated_text': '一 千 朵 雪 落 无 声 ↲ 我 把 日 子 铸 成 它 ↲ 填 进 泥 土 ↲ 填 满 一 个 < 亲 近 小 屋 ↲↲ 废 的 日 子 ↲ 像 一 堆 无 知 的 树 ↲ 浓 雾 裹 住 我 的 门 ↲↲ 我 的 四 周 ↲ 被 春 风 遗 忘 着 ↲ 出 我 的 双 手 ↲↲ 伤 口 ， 偷 偷 ↲ 我 的 声 音 被 你 伤 痛 ↲ 我 被 你 的 带 领 ↲ 震 撼 浓 云 ↲↲ 我 不 能 痛 饮 ↲ 那 不 能 抵 抗 的 ↲ ↲ 的 ↲↲ 尖 的 雪 ↲ 的 ↲ ↲ 如 ↲ ↲ 满 床 ↲ 星 ↲ 如 ↲ 一 个 ↲ 星 星 ↲ 然 ↲ ↲ ↲ ↲ 我 ↲ 的 ↲ 星 ↲ 不 醒 ↲ ↲ 说 ↲ 奔 跑 ↲ 掠 过 ↲ 我 ↲ ↲ 我 的 ↲ ↲ 星 ↲ ↲ ↲ 星 星 ↲ 我 ↲ ↲ ↲ ↲ 掠 ↲ 我 的 不 能 ↲ 我 ↲ 古 劫 持 续 的 ↲ 我 ↲ ↲ 星 ↲ 星 星 星 星 ↲ 我 的 ↲ 我 ↲ ↲ 我 ↲ 我 的 ↲ ↲ 我 ↲ 星 ↲ ↲ 星 星 星'}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generator(\"一 千 朵 雪 落 无 声 ↲ 我 把 日 子 铸 成 它 ↲ 填 进 泥 土 ↲\", max_length=256, do_sample=True,top_k=5, top_p=0.95, num_return_sequences=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[{'generated_text': '梅花落满了南山 ↲ 啊 ， 多 少 人 看 多 了 江 南 阴 冷 ↲↲ 这 个 月 我 多 么 渴 望 能 够 ↲ 当 我 看 到 你 开 花 了 ↲ 你 的 日 子 正 变 成 一 条 金 色 的 小 河 ↲ 这 是 我 对 你 无 言 的 流 向 ↲ 西 的 这 块 麦 田 ↲↲ 这 是 你 的 灵 魂 ↲ 你 手 里 紧 握 着 麦 穗 ↲ 你 含 泪 的 彩 色 ↲ 肯 定 留 下 我 在 这 里 ↲ 入 我 的 眼 睛 ↲↲ 尖 的 树 林 ↲ 一 切 ↲ 我 ↲ ↲ 我 的 持 你 ， 4 笑 ↲ 我 ↲ 我 ↲ 我 ↲ 裂 ↲↲ 我 的 ↲ 古 树 冠 冕 ↲ 我 ↲ 我 的 热 ↲ 我 ↲ 我 的 小 话 ↲ 我 的 ↲ ↲ 我 的 ↲ ↲ 我 的 窗 ↲ 鱼 宫 殿 堂 的 人 的 小 事 ↲ 我 ↲ 我 站 在 泥 土 摇 晃 动 ， 我 ↲ 一 道 路 上 ↲ 我 ↲ 我 的 人 ↲ 我 ↲ 我 的 小 宫 殿 堂 ↲ ↲ 我 ， ↲ 我 ↲ 我 的 心 事 ↲↲ 叶 荫 的 心 ↲ 的 ↲ 我'},\n",
    " {'generated_text': '梅花落满了南山 ↲ 一 千 年 的 寒 风 ↲↲ 七 月 ， 那 人 来 得 满 园 子 的 一 生 ↲ 定 在 谷 外 拋 锚 的 花 园 围 栏 ↲↲ 我 看 见 你 长 大 了 饥 饿 的 名 字 ↲ 一 下 ， 你 的 名 字 在 山 谷 ↲ 仿 佛 一 粒 黏 星 ↲↲ 我 穿 著 绿 洲 的 草 坡 ↲ 又 一 坡 的 寂 寞 ↲ 金 黄 的 手 指 插 满 了 风 ↲↲ 我 的 心 情 ↲ 我 要 贴 着 白 沙 的 青 苔 ↲ 贴 到 蓝 色 的 胸 膛 ↲ ↲ ↲ 绒 上 ↲ 我 的 床 ↲ 我 的 心 灵 魂 魄 ↲ 上 游 荡 的 柔 和 你 的 天 空 气 息 虚 伪 装 饰 ↲↲ 午 睡 梦 的 浊 的 心 ↲ 我 的 心 ↲ 我 的 床 边 ↲ 络 时 候 鸟 ↲ 的 心 ↲ 的 日 子 里 ， ↲ 让 我 的 日 子 的 心 的 日 子 上 ↲↲ 我 ↲↲ 我 的 ↲↲ 的 早 晨 曦 ↲ 黄 昏 暗 绿 ↲↲ 尖 锐 利 的 阳 光 焰 ↲ 面 ↲ 全 部 分 ↲ 让 我 日 子 的 心 里 ，'},\n",
    " {'generated_text': '梅花落满了南山 ↲↲ 冬 日 的 雨 下 在 江 湖 ↲ 江 湖 注 定 是 你 诗 中 的 一 个 险 句 ↲↲ 不 如 学 仙 去 ↲ 无 端 端 的 你 ↲ 不 能 不 去 ↲↲ 你 是 我 的 好 友 ↲ 你 是 我 的 朋 友 ↲ 我 们 是 你 的 兄 弟 ↲ 你 是 我 的 朋 友 ↲ 永 远 在 你 的 心 里 ↲ 你 是 一 首 诗 ↲↲ 你 是 一 朵 看 到 的 ↲ 你 的 眼 睛 ↲ 永 不 用 的 思 想 ↲ 永 不 长 的 ↲↲ 你 来 了 ↲ ↲ ↲ 的 ↲ ↲ ↲ 你 的 ↲ 哪 一 巴 ↲ 一 滴 ↲ 哪 一 个 ↲ ↲ 我 的 ↲ ↲ 我 ↲ 船 ↲ ↲ ↲ 我 ↲ 你 走 ↲ 到 你 的 ↲ 你 走 了 ↲ 你 ↲ 我 的 ↲ 的 ↲ 你 的 ↲ 我 的 你 的 ↲ ↲ ↲ ↲ ↲ ↲ ↲ 的 ↲ 你 的 ↲ ↲ 掠 价 ↲ 掠 过 ↲ 你 的 ↲ 你 掠 过 ↲ ↲ 我 的 ↲ ↲ 我 ↲ ↲ ↲ ↲ ↲ 你 的 ↲ 于 忧 愁 ↲'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[{'generated_text': '夜空中最亮的星， 这 是 爱 ， 就 此 一 生 ， 愿 我 的 我 的 吻 ， 一 再 爱 ， 也 许 是 我 真 ， 想 对 你 ， 狂 妄 代 价 ， 会 些 为 了 ， 这 种 罪 ， 我 爱 你 ， 没 有 未 能 令 我 的 手 ， 嗯 。 ， 不 要 独 立 生 活 下 也 记 忆 为 我 们 的 心 恼 ， 明 天 可 躲 ， 当 我 的 我 这 单 车 ， 失'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '{冬}<3>[梅花,雪,寒冷,思念]梅花落满了南山，像一地的雪， ， ， ， 一 样 。 ， 的 海 滩 的 小 草 滩 ， ， ， 还 是 得 很 早 年 的 ， 在 海 洋 的 的 人 类 似 的 时 间 的 尽 头 ， 。 ， ， 的 得 很 远 方 ， 我 的 的 一 个 时 候 。 ， 地 上'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generator(\"\\{冬\\}<>[梅花,雪,寒冷,思念]梅花落满了南山，像一地的雪，\", max_length=128, do_sample=True,top_k=5, top_p=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator(\"最美的不是下雨天，是曾与你躲过雨的屋檐\", max_length=256, do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator(\"当两颗心开始震动,当你瞳孔学会闪躲\", max_length=100, do_sample=True)\n",
    "text_generator(\"当两颗心开始震动,当你瞳孔学会闪躲\", max_length=100, do_sample=True,     top_k=5, top_p=0.9, num_return_sequences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator(\"当 两 颗 心 开 始 震 动 \", max_length=100, do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator(\"当两颗心开始震动，\", max_length=100, do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, GPT2LMHeadModel, TextGenerationPipeline\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"uer/gpt2-chinese-lyric\")\n",
    "# model = GPT2LMHeadModel.from_pretrained(\"uer/gpt2-chinese-lyric\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"/localdata/workspace/UER-py/models/clyric\")\n",
    "model = GPT2LMHeadModel.from_pretrained('/localdata/workspace/UER-py/models/clyric')\n",
    "text_generator = TextGenerationPipeline(model, tokenizer)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " [{'generated_text': '最美的不是下雨天，是曾与你躲过雨的屋檐 ， 下 课 铃 声 响 起 的 瞬 间 ， 我 们 的 笑 脸 ， 有 太 多 回 忆 在 浮 现 ， 是 你 总 在 我 身 边 ， 不 知 道 会 不 会 再 见 ， 从 现 在 开 始 到 永 远 ， 想 说 的 语 言 凝 结 成 一 句 ， 不 管 我 们 是 否 能 够 兑 现 ， 想 说 的 语 言 凝 结'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': '请以“梅花落满了南山”为题写一首诗：“梅花落满了南山,枝头遍插梅花”。 \\n“梅花落满了南山,枝头遍插梅花”,是说梅花是梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根,梅花的根'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLNetTokenizer, GPT2LMHeadModel\n",
    "from transformers import TextGenerationPipeline\n",
    "import jieba\n",
    "# add spicel process \n",
    "class XLNetTokenizer(XLNetTokenizer):\n",
    "    translator = str.maketrans(\" \\n\", \"\\u2582\\u2583\")\n",
    "    def _tokenize(self, text, *args, **kwargs):\n",
    "        text = [x.translate(self.translator) for x in jieba.cut(text, cut_all=False)]\n",
    "        text = \" \".join(text)\n",
    "        return super()._tokenize(text, *args, **kwargs)\n",
    "    def _decode(self, *args, **kwargs):\n",
    "        text = super()._decode(*args, **kwargs)\n",
    "        text = text.replace(' ', '').replace('\\u2582', ' ').replace('\\u2583', '\\n')\n",
    "        return text\n",
    "\n",
    "tokenizer = XLNetTokenizer.from_pretrained('mymusise/CPM-Generate-distill')\n",
    "model = GPT2LMHeadModel.from_pretrained(\"mymusise/CPM-Generate-distill\")\n",
    "\n",
    "text_generater = TextGenerationPipeline(model, tokenizer)\n",
    "\n",
    "print(text_generater(\"请以“梅花落满了南山”为题写一首诗：\", max_length=256, top_k=1, use_cache=True, prefix=''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '请以“梅花落满了南山”为题写一首诗： \\n山色空蒙雾雨浓,春色葭空。\\n葭苍苍白露隅,悠悠我心忧悠悠。\\n葭随风去,白露皎洁月明中。\\n葭苍苍野落尽,青枫不知晓。\\n悠悠我心忧悠悠。 \\n葭苍苍白露隅,悠悠我心忧悠悠。\\n葭苍苍野落尽,青枫不知晓。 \\n悠悠我心忧悠悠。 \\n葭苍苍野落尽,青枫不知晓。\\n悠悠我心忧悠悠。 \\n葭苍苍野落尽,青枫不知晓。\\n悠悠我心忧悠悠。\\n葭苍苍野落尽'},\n",
       " {'generated_text': '请以“梅花落满了南山”为题写一首诗： \\n“梅花落满南山, \\n梅花落满南山。 \\n“南山”,是指南山。“南山”是指南山。 \\n“梅花落满南山”,是指南山。“梅花落满南山, \\n梅花落满南山。”这两句诗的句式是“梅花落满南山, \\n梅花落满南山。”“梅花落满南山, \\n梅花落满南山。”句式,是由句式的“梅花落满南山, \\n梅花落满南山。”, \\n和句式的“梅花落满南山, \\n梅花落满南山。” \\n这两句诗的结构是“梅花落满南山, \\n梅花落满南山。”句式,是由句式的'},\n",
       " {'generated_text': '请以“梅花落满了南山”为题写一首诗：“梅花落满了南山”,“南山”即指南山。\\n如何看待2016年10月15日的股市分析?  【10月15日】股市分析 【10月15日】今日股市分析 【10月15日】大盘分析 【10月15日】创业板、绩优股、创业板、创业板指数 【10月15日】                                                              '}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generater(\"请以“梅花落满了南山”为题写一首诗：\", max_length=256, do_sample=True, use_cache=True, top_p=0.9, top_k=5, num_return_sequences=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49a4d35495a0ee52f35720c27c94986b4a3077a71a8c6157808376aed5c51fad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
